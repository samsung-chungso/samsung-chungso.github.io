---
published: true
layout: splash
classes:
  - landing
  - dark-theme
title: '[CS231n 강의노트] Lecture2'
---

> Standford University의 cs231n 강의를 정리한 내용입니다.
# Lecture2. Image Classification
## Image Classification
#### motivation & example
Image classification은 전체 이미지를 보고 특정 카테고리(예. 고양이, 자동차)로 레이블을 분류하는 것입니다. 컴퓨터 비전 측면에서 이미지는 어떤 의미를 가진다기보다는 숫자로 구성된 큰 3차원 배열입니다. 너비 Width x 높이 Height x 3 으로 구성되어 있고, 각 픽셀에 들어가는 수는 0(검정)부터 255(하얀색)으로 구성되어 있으며 채널 3(x 3)은 Red, Green, Blue입니다.
#### chanllenges
컴퓨터 비전 입장에서 이미지는 수로 이뤄진 배열의 집합이기 때문에 사람처럼 이미지를 보고 인식하는 것은 어렵습니다. 특히 다음 7가지 챌린지가 있습니다.
- Viewpoint variation: 촬영 각도
- Scale variation: 꼭 사진 크기가 아니더라도 객체 크기의 다양성
- Deformation: 다른 자세
- Occlusion: 살짝 가려짐
- Illumination conditions: 조명
- Background clutter: 배경과 보호색을 이룸
- Intra-class variation: 동일한 객체도 다양한 생김새

#### data-driven approach
챌린지를 해결하고자 데이터 기반으로 접근했던 방식을 알아보겠습니다. 만약 데이터 기반이 아닌 특정 고양이 이미지의 edge를 인식하는 알고리즘을 만든다 라고 한다면, 조금이라도 달라진 고양이 이미지에 대해 또는 위 챌린지를 가진 이미지에 대해 알고리즘은 동작하지 않을 것입니다. 따라서 모든 객체마다 이미지를 인식할 수 있는 알고리즘을 구현하는 것 대신 어린아이에게 가르치듯이 특정 클래스(예. 고양이)에 해당하는 많은 이미지를 보여주는 방식을 택하고, 클래스가 라벨링된 이미지를 축적했습니다. 
#### image classification pipeline
Image classification에서 파이프라인은 다음과 같이 형성되었습니다. 
- Input: N개의 이미지를 가지고 K개의 다른 클래스가 라벨링되어 있습니다. 그리고 머신러닝에서 사용한 단어와 동일하게 training set이라고 부릅니다.
- Learning: 개별 클래스가 어떻게 생겼는지 training set기반으로 학습합니다. 이 과정을 training classifier 또는 모델을 학습한다(learning a model)고 합니다.
- Evaluation: 학습한 모델(혹은 classifier)의 라벨 예측 성능을 평가하는 단계가 마지막에 있습니다. 실제 라벨(ground truth)과 비교했을 때 얼마나 잘 예측하는 지 판단합니다.

## Nearest Neighbor Classifier
Machine Learning 기반의 classifier는 Nearest Neighbor입니다. 모든 샘플 데이터를 기억하고, 비슷한 이미지를 픽셀값 기반으로 계산하는 방식으로 추천하는 classifier는 아니지만, 이미지 분류 문제에 대한 기초적인 접근을 위해 코드도 구현해보고 배울 것입니다.
### Example image classification dataset: CIFAR-10
Image classification에서 사용한 고전적인 데이터셋으로 CIFAR-10 데이터(시파텐)가 있습니다. 32픽셀 저화질, 10개의 클래스로 라벨링된 60,000개의 이미지라고 합니다. 그리고 머신러닝에서 하듯이 train, test로 데이터를 나눠줍니다. Train에 사용되지 않은 test 데이터를 가지고 분류를 진행해보면, 10개 중 3개 정도 맞출 정도의 낮은 성능을 가지고 있습니다. 그럼 어떻게 이 3개 정도는 비슷한 이미지라고 판단했느냐? 하면 두 이미지의 픽셀값끼리의 거리 연산을 통해 유사도를 계산했습니다. L1 distance입니다.

$$ d_1(I_1, I_2) = \left\lvert\displaystyle\sum_{p}I_1^P-I_2^P\right\rvert$$


두 이미지의 픽셀값을 P1, P2 하나씩 불러와서 값 차이의 절대값을 구함으로써 유사도를 계산하는 것입니다. L1 distance 계산하는 방식으로 CIFAR-10 데이터셋은 38.6% 의 정확도를 달성했습니다. 벡터간의 거리를 계산하는 방식으로 L1 distance를 택한 것이지 이 외에도 거리 계산 방식은 다양하게 존재합니다. 두 개의 벡터 사이의 유클리드 거리를 계산하면 L2 distance입니다.

$$d_1(I_1, I_2) = \sqrt{(\displaystyle\sum_{p}I_1^P-I_2^P^2)}$$

L2는 CIFAR-10 데이터에 대해서 35.4%의 정확도를 달성했다고 합니다. 


### L1 vs. L2
L1보다 낫고, L1은 벡터의 좌표에 영향을 받지만, L2는 벡터의 좌표에 구애받지 않기 때문에 벡터의 위치가 중요하다면 L1이 더 나은 선택이라고 합니다. 


## k-Nearest Neighbor Classifier
L1 distance로 위치가 유사한 픽셀값끼리만 가지고 라벨을 판단하는 데에는 한계가 있어, 우리는 k개의 가장 가까운 이미지를 가지고 라벨을 투표하는 방식인 k-Nearest Neighborhood classifier를 구상하게 되었습니다. 다수결 voting 방식으로 k를 늘려나가면 클러스터 형성을 하고 decision boundary를 단일 이미지를 비교할 때보다 smooth하게 만들고 robust한 모델을 만들 수 있습니다. 따라서 test data에 보다 정규화된 성능을 가지게 됩니다.


## Validation sets for Hyperparameter tuning
Machine Learning 처럼 L1, L2 어떤 걸 선택할 거냐 등 hyperparameter를 튜닝하기 위해서 validation set의 준비 중요성을 강조합니다. Test set은 최종 단계에서 한번만 사용하여 overfit을 방지해야 합니다. Validation set과 Test set을 training set과 별도로 분리함으로써 우리는 모델, classifier를 정규화 정도를 잘 판단할 수 있을 것입니다.
### Cross-validation
Machine Learning에서 배운 내용과 동일하게 training data의 크기가 작다면, validation set을 많이 만들기 위해서 cross-validation 기법을 사용합니다. 예시로 Training set을 5개의 동일한 fold를 만들고, 5개의 fold가 돌아가면서 validation set의 역할을 하며 모델의 성능을 평가하는 기법입니다. 
### In practice
### Pros and Cons of Nearest Neighbor classifier
살짝 음영이 들어간 이미지를 뜻하는 tinted 이미지의 경우 NN classifier로 같은 이미지임을 판정하지 못한다는 단점이 있습니다. 또한 전혀 사용되지 않는 point가 있다는 것도 단점입니다. 
그러나 NN classifier는 이미지를 train하는 데에 시간과 컴퓨터 

## Linear Classifier
앞으로 배울 CNN의 구성에 많은 영향을 끼친 Linear Classifier는 레고처럼 쌓을 수 있는 layer를 가집니다. 이 모델은 train dataset은 더이상 필요 없어졌고, 계산에 필요한 함수 f(x)만 필요할 뿐입니다. 
![IMG_2CD7A4B7BAA3-1.jpeg]({{site.baseurl}}/_posts/IMG_2CD7A4B7BAA3-1.jpeg)
Linear classifier의 장점은 
Linear classifier의 단점은 많은 이미지들 분류에 적합하지 않다는 것입니다. 하나의 템플릿 f(x)로 카테고리를 판단하기 때문에 클래스의 변형이 있는 경우, 평균으로 계산해버리고


#### 출처
CS231n 강의:https://www.youtube.com/watch?v=OoUX-nOEjG0&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=2
