---
published: true
layout: splash
classes:
  - landing
  - dark-theme
title: '[CS231n 강의노트] Assignment 1: Q1. k-Nearest Neighbor classifier'
use_math: true
tags:
- image classification
- cs231n
- kNN classifier
---

> Standford University의 cs231n 강의를 정리한 내용입니다.
> 과제 1의 풀이를 정리해보려고 합니다.


# Q1. k-Nearest Neighbor classifier
## k-Nearest Neighbor (kNN) exercise
### knn.ipynb

#### classifier 이용해서 이미지의 라벨 예측하기
kNN classifier는 두 단계로 구성되어 있습니다.
- Train 단계에서 classifier는 training 데이터(CIFAR-10)를 받고, 모두 기억합니다.
- Test 단계에서, kNN classifier는 모든 테스트 이미지를 training 데이터인 이미지들과 비교하고, training 데이터의 최근접 라벨로 변환합니다.

Train 단계이자, Test 단계 전에 training 데이터(CIFAR-10)의 차원을 변경해줍니다. training 데이터는 이미지 데이터로 4차원으로 구성되어서 X_train, X_test에 저장됩니다. training 데이터의 라벨 정보는 y_train, y_test에 1차원으로 저장됩니다.

<img width="351" alt="image" src="https://github.com/samsung-chungso/samsung-chungso.github.io/assets/103614665/47ca5cd0-a1cd-486b-8da1-758dff213022">


이미지 픽셀별 값을 넘파이 배열로 불러올 때에는 기존 4차원으로 구성된 값들을 reshape 함수를 이용해 2차원으로 변경해줍니다. 5000개의 이미지를 5000개의 행으로 가지고, 열은 알아서 숫자 맞춰달라는 표시로 -1값을 reshape 함수의 변경할 차원 parameter(newshape)로 넣어줍니다. Test 데이터도 동일한 차원으로 변경을 합니다. 물론 500개의 데이터이기 때문에, 행의 갯수는 500으로 달라집니다. 알아서 맞춰준 열은 32x32x3으로 3,072입니다.

    X_train = np.reshape(X_train, (X_train.shape[0], -1))
    X_test = np.reshape(X_test, (X_test.shape[0], -1))

Test 단계는 두 과정으로 나눠볼 수 있겠습니다.

  1. 모든 Train, Test 데이터의 거리값을 계산합니다. L2 distance인 유클리디안 거리 공식을 사용하겠습니다.
        $$d_2(I_1, I_2) = \sqrt{\displaystyle\sum_{p}(I_1^P-I_2^P)^2}$$
  2. 계산된 거리값을 기반으로 Test 데이터와 가까운 k개의 Train 데이터를 찾고, 라벨값의 다수결을 뽑습니다.

Train, Test 데이터의 거리값을 3가지 방식으로 계산해보겠습니다. knn.ipynb 에서 compute_distances_two_loops()를 사용하고 함수가 정의된 파일은 k_nearest_neighbor.py 입니다. Test 결과 이미지를 먼저 보여드리자면, 500x5000 흑백 픽셀로 표현됩니다.

<img width="834" alt="image" src="https://github.com/samsung-chungso/samsung-chungso.github.io/assets/103614665/d3be5b71-0166-4667-a8c9-40d28a402152">


**2개 루프로 계산하기**
**compute_distances_two_loops()**

X로 Test 데이터를 받고, X_train으로 Train 데이터를 받아서 for loop로 각각 이미지 갯수만큼 5000번, 500번 돌려줍니다. X_train[j]로 Train 데이터 j번째 이미지 전체 픽셀값이 하나의 행으로 불러와집니다. X[i]로 Test 데이터 i번째 이미지 전체 픽셀값이 하나의 행으로 불러와집니다. 두개의 for loop를 활용해서 Test 데이터 i번째 이미지를 모든 Train 데이터 픽셀값과 비교하고, 또 i+1번째 이미지를 모든 Train 데이터 픽셀값과 비교하고,,, 그리고 L2 distance 값을 수식 그대로 계산 해줍니다.

*힌트:*  
*i번째 Test 데이터의 지점과 j번째 Train 데이터의 지점의 L2 distance를 계산하고 dists[i,j]에 저장하기*

    def compute_distances_two_loops(self, X):
        num_test = X.shape[0]
        num_train = self.X_train.shape[0]
        dists = np.zeros((num_test, num_train))
        for i in range(num_test):
            for j in range(num_train): 
                distance = np.sqrt(np.sum(np.square(self.X_train[j]- X[i])))
                dists[i,j] = distance
        return dists

**1개 루프로 계산하기**
**compute_distances_one_loop()**

위에서 2개의 for loop을 사용하다보니 너무 시간이 오래 걸립니다. 1개의 loop만 사용하겠습니다. numpy는 연산이 가능하도록 서로 다른 배열의 크기를 자동으로 맞춰는 broadcasting 기능이 있어 굳이 for loop 인덱스 j로 Train 데이터를 전부 Test데이터 i와 비교하는 것이 아닌, 자동으로 Train 데이터 전체를 Test i번째 데이터를 broadcast해서 연산할 수 있도록 Test 데이터만 for loop로 돌려주도록 하겠습니다.

*힌트:*  
*i번째 Test 데이터의 지점과 모든 Train 데이터 지점들의 L2 distance를 계산하고 dist[i,:]에 저장하기*

    def compute_distances_one_loop(self, X):
        num_test = X.shape[0]
        num_train = self.X_train.shape[0]
        dists = np.zeros((num_test, num_train))
        for i in range(num_test):
            distance = np.sqrt(np.sum(np.square(self.X_train - X[i,:]), axis = 1))
            dists[i, :] = distance
        return dists

**루프 없이 계산하기**
**compute_distance_no_loops()**

broadcast를 한번 써봤으니 broadcast 하나 더 쓰면 for loop 아예 없앨 수 있지 않을까?라는 아이디어가 있습니다. 

*힌트:*  
*행렬곱(matrix multiplication)과 두개의 broadcast 합을 이용해서 구하시오.*

L2 distance 공식 안의 제곱근을 풀어줍니다. 힌트 정보에 따라 뺄셈보다는 곱이 잔뜩 들어간 공식으로 바꿀 수 있습니다.   

        $$(I_1^P-I_2^P)^2 = (I_1^P)^2 - 2 I_1^P I_2^P + (I_2^P)^2, $$
        $$\quad d_2(I_1, I_2) = \sqrt{\displaystyle\sum_{p}(I_1^P)^2 - \displaystyle\sum_{p}2I_1^PI_2^P + \displaystyle\sum_{p}(I_2^P)^2}$$  

numpy sum의 keep dimension 기능을 이용해서 위 식의 첫번째, 세번째 항을 구해줍니다. 두번째 항은 X_train을 transpose한다면, 수학 행렬에서 내적하듯한 결과를 내는 dot 연산을 이용해 행렬곱(matrix multiplication)을 쉽게 계산할 수 있습니다.
  
    def compute_distances_no_loops(self, X):
        num_test = X.shape[0]
        num_train = self.X_train.shape[0]
        dists = np.zeros((num_test, num_train))
        
        i_1_sq_sum = np.sum(X**2, axis=1, keepdims=True)
        i_2_sq_sum = np.sum(self.X_train**2, axis=1, keepdims=True)
        dists = np.sqrt(-2*X.dot(self.X_train.T)+i_1_sq_sum+i_2_sq_sum.T)
        return dists
        

**Inline Question 1**
- What in the data is the cause behind the distinctly bright rows?  
픽셀값은 0에 가까울수록 검정색, 255에 가까울수록 흰색을 나타냅니다. 거리값으로 픽셀값을 계산했으니, 거리가 멀수록 큰값을 가지므로 흰색 표시는 이미지가 차이가 많다는 것을 알 수 있습니다. 
  
- What causes the columns?  
columns 하나하나가 Train 이미지 하나를 의미하므로 column 한 줄은 Train 이미지 기준으로 Test 이미지와 차이가 있을 수록 흰색을, 차이가 없을 경우 검정색을 의미합니다.

#### Cross-validation 구현해보기

**Train 데이터 k fold**

*힌트:*
*training data를 fold 안에 쪼개서 넣습니다. numpy array_split 함수 사용하면 쉽습니다*
    
    X_train_folds = np.array_split(X_train, num_folds)
    y_train_folds = np.array_split(y_train, num_folds)


**Validation set k fold**

*힌트:*
*쪼갠 fold 갯수 k만큼 k-nearest-neighbor 알고리즘 실행시켜서 최적의 k를 찾습니다. k-1개의 케이스에 대해서는 training data를 사용하고, 마지막 한개에 대해서는 validation data를 사용하여 k값별 정확도를 딕셔너리에 넣어 줍니다.*

    for k in k_choices:
        k_to_accuracies[k] = []
        for i in range(num_folds):
            X_train_temp = np.concatenate([fold for j, fold in enumerate(X_train_folds) if j != i])
            y_train_temp = np.concatenate([fold for j, fold in enumerate(y_train_folds) if j != i])
            X_valid = X_train_folds[i]
            y_valid = y_train_folds[i]
        
            classifier = KNearestNeighbor()
            classifier.train(X_train_temp, y_train_temp)
        
            dists = classifier.compute_distances_no_loops(X_valid)
            y_valid_pred = classifier.predict_labels(dists, k=k)
        
            num_correct = np.sum(y_valid_pred == y_valid)
            accuracy = float(num_correct)/len(y_valid)
            k_to_accuracies[k].append(accuracy)


cross validation 결과, 가장 적절한 k값은 12 정도로 보이네요.

<img width="854" alt="image" src="https://github.com/samsung-chungso/samsung-chungso.github.io/assets/103614665/ae771ae2-eb07-4805-ae9e-4b1819890c6b">


#### 출처
- CS231n 강의:(https://cs231n.github.io/assignments2024/assignment1/)
Assignment tutorial 올려주신 조교님이 한국계이신 것 같네요
- J Lee 풀이
- 넘파이에서 유클리드 거리 제곱 풀기: (https://stackoverflow.com/questions/64952027/compute-l2-distance-with-numpy-using-matrix-multiplication)
