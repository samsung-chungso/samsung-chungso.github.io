---
layout: splash
classes:
  - landing
  - dark-theme
title: '[CS231n 강의노트] Lecture1'
---


# Lecture1. Introduction to Convolutional Neural Networks for Vision Recognition

### 컴퓨터 비전의 큰 흐름
 생물학적 vision(시각)의 발전은 폭발적인 개체 수 증가로 생물을 진화시켰듯이 vision은 모든 분야에서 활용되는 다학제적 학문입니다. 기계에서 vision은 카메라 발달과 같이 역사가 있었고, 동물은 어떤 생물학적 원리로 vision을 사용할 수 있는지 연구가 있어 왔었습니다. 
 
 컴퓨터로도 vision을 구현하려는 여러 시도가 있었습니다. 시작은 물체를 컴퓨터는 어떻게 구분할까에 대한 연구였습니다. 역사적으로 아래와 같은 연구 및 연구자가 큰 영향을 끼쳤습니다.
- A Block World: 물체를 구분하고 인식하는 방법
- The Summer Vision Project
- David Mart
	- 입력 image
    - primary sketch: 이미지의 가장자리, 끝 등 곡선이나 경계를 표현
    - 1/2D sketch: 깊이정보, 표명, 레이어 등 불연속성 구분
    - 3D
    
 컴퓨터로 현실세계를 표현하고자 하는 노력도 있었습니다.
- Generalized Cylinder / Pictorial Structure: 복잡한 물체의 구조를 간단한 모양, 기하학적 구성으로 변환
- David Lowe: 면도기 이미지 edge 따기

 앞에서 언급한 방법처럼 이미지에서 객체를 인식하는 것이 오랜시간 어려웠던 문제로 꼽을 수 있겠습니다. 진행해왔던 프로젝트들도 사실상 toy 프로젝트에 불과하며 실세계 문제에 적용하기에는 어려움이 있었습니다. 
 
 객체 인식을 위해서 시작은 object segmentation 연구였습니다. 픽셀 단위로 같은 semantic(의미론적) 분류를 하였습니다. 그 이후에 사람의 부위 중 가장 중요하다는 얼굴 인식을 하게 됩니다. 얼굴 인식은 머신러닝 기술의 성장과 함께 비약적으로 성장할 수 있었습니다. 실시간으로 얼굴을 인식하는 알고리즘인 AdaBoost가 나왔고, toy 프로젝트에 멈추지 않고 실제 후지 필름 카메라에 적용됨으로써 실세계 문제에 사용되었습니다. 객체 인식에서 'feature based'가 등장한 "SHIF" 피처도 등장하였습니다. 
- Normalized Cut
	- 그래프 이론 알고리즘
- Face Detection    
	- AdaBoost
- "SHIF" & Object Recgnition
    
 컴퓨터 비전에서 이미지의 피처를 잡아내는 것은 오히려 쉬웠고 어려운 문제는 전체 이미지를 인식하고 어떤 유형의 이미지인지 의미론적으로 판단하는 것이었습니다. 이미지 전체의 의미를 잡아내기 위해 벡터 머신 알고리즘을 만들어 내었습니다. 이처럼 사실적인 이미지에서 몸의 구성요소를 보고 인식하고자 했던 연구가 있었습니다.
- Histogram of Gradient
- Deformable Part Model

 컴퓨터 비전의 역사 속 연구들에서 변화구가 발생했는데요.
- 이미지 품질 향상 
- 문제 정의를 object recognition 지정
 
 이 변화로 인해 컴퓨터 비전은 드라마틱하게 성장하게 됩니다. 이미지 데이터셋을 구성하자는 의견은 2000년대 초반부터 있었고, PASCAL VOC 중심으로 발전하였습니다. 그리고 물체 인식의 성능 평가 지표 알고리즘을 구성하였습니다. 
 
 IMAGENET 프로젝트는 두 가지 목적으로 시작하게 되었습니다.
- 세상 모든 객체를 인식하고 싶음
- 이미지 데이터 과적합 문제 해결
 IMAGENET recognition challenge 를 통해 컴퓨터 비전 알고리즘은 불과 몇년만에 사람만큼 인식하는 수준이 되었습니다. 2012년 부터 딥러닝이라 할 수도 있는 Convolutional Neural Network 등장으로 물체 인식의 오류률을 크게 낮췄습니다.

### CNN
 Image Classification은 이미지를 특정 카테고리로 골라서 지정하는 것입니다. 이를 위해 다음 두 가지를 해야 합니다.
- Object Detection
- Image Captioning

 IMAGENET recognition challenge를 보면, 2010년까지 머신러닝 모델이 네개 정도의 계층적인 모델을 가집니다. 2012년 그당시 'SuperVision'이라 불린 AlexNet부터 계층이 7~8개 가지고, neural network이 우승을 하기 시작합니다. 계층은 계속 증가를 했고, CNN의 획기적인 성능 등장 이후부터는 기존의 CNN을 조금씩 변경해나가는 데에 초점을 맞췄습니다.
 
 CNN의 개념이 처음 등장한 것이 2012년은 아니며, 90년대 LeCun의 손글씨를 픽셀 기반으로 classification하기 위한 모델이 연구되었던 적이 있었는데 이는 CNN과 매우 유사하다.
 
### 마무리
 컴퓨터 비전은 지금 혁신적인 발전을 해왔는데, 핵심 요인은 다음 두 가지이다.
- Computing: registor, GPU
- 데이터: 레이블링이 된 이미지 데이터

 컴퓨터 비전 사람처럼 볼 수 있는 기계를 만들고자 하고, 아직 해결되어야 하는 문제가 많습니다. 이제는 단순히 객체를 인식하는 것이 아닌 객체들 간의 관계를 파악하려는 노력이 이뤄지고 있습니다. 또한 미결된 문제의 한 예로, 사진을 보고 그 너머의 사진이 의미하는 story를 빠른 시간 내로 파악하는 데 문제가 있습니다. (2017년 강의 자료)
 
 
#### 출처
CS231n 강의: https://www.youtube.com/watch?v=vT1JzLTH4G4&t=27s

